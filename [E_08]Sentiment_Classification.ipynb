{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! ln -s '~/data/*.txt' '/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UuUYhZG0JV7",
        "outputId": "fdee7464-9663-4bd1-af44-9f9953b90d5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link '/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/*.txt': File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 -m pip install konlpy"
      ],
      "metadata": {
        "id": "tqV9pGmxy-sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65926b0-af02-490f-c8fb-3b045939ad00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sLWnRI_vaBx",
        "outputId": "8edda79e-5530-46b7-b568-c2f07fee2a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n",
            "0.6.0\n",
            "3.6.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import konlpy\n",
        "import gensim\n",
        "\n",
        "print(pd.__version__)\n",
        "print(konlpy.__version__)\n",
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip install konlpy JPype1-py3\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwmBSXKYzIFE",
        "outputId": "218fae5b-6c14-44d4-bb73-2d37a3bab47e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u342-b07-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1-py3 in /usr/local/lib/python3.7/dist-packages (0.5.5.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Mecab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EkFGv0_YEMy",
        "outputId": "bf76bc38-7e70-4931-8632-a7212a511b58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Mecab in /usr/local/lib/python3.7/dist-packages (0.996.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "import numpy as np\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "3EnqtmWyz2mL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비와 확인"
      ],
      "metadata": {
        "id": "pwJs4GhaWLoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 읽어봅시다. \n",
        "train_data = pd.read_table('/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/ratings_test.txt')\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HmxxUphyWNMU",
        "outputId": "41b713b0-9b87-4f2e-b3b4-74edd9e5ceb5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a6aa01b-ef23-4003-a24e-fe7c6f5e80d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a6aa01b-ef23-4003-a24e-fe7c6f5e80d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a6aa01b-ef23-4003-a24e-fe7c6f5e80d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a6aa01b-ef23-4003-a24e-fe7c6f5e80d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로더 구성"
      ],
      "metadata": {
        "id": "7cmW-Ytebgen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "from MeCab import Tagger\n",
        "\n",
        "tokenizer = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "def load_data(train_data, test_data, num_words=10000):\n",
        "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    train_data = train_data.dropna(how = 'any') \n",
        "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    test_data = test_data.dropna(how = 'any') \n",
        "    \n",
        "    X_train = []\n",
        "    for sentence in train_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
        "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "        X_train.append(temp_X)\n",
        "\n",
        "    X_test = []\n",
        "    for sentence in test_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
        "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "        X_test.append(temp_X)\n",
        "    \n",
        "    words = np.concatenate(X_train).tolist()\n",
        "    counter = Counter(words)\n",
        "    counter = counter.most_common(10000-4)\n",
        "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
        "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
        "        \n",
        "    def wordlist_to_indexlist(wordlist):\n",
        "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
        "        \n",
        "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
        "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
        "        \n",
        "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
        "    \n",
        "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
      ],
      "metadata": {
        "id": "dg7MT-njWNRG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index:word for word, index in word_to_index.items()}"
      ],
      "metadata": {
        "id": "5Llq6ke-WNO5"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
        "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
        "def get_encoded_sentence(sentence, word_to_index):\n",
        "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
        "\n",
        "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
        "def get_encoded_sentences(sentences, word_to_index):\n",
        "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
        "\n",
        "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
        "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
        "\n",
        "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
        "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
        "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
      ],
      "metadata": {
        "id": "xx132BWgbqGC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구성을 위한 데이터 분석 및 가공\n",
        "\n",
        "* 데이터셋 내 문장 길이 분포\n",
        "* 적절한 최대 문장 길이 지정\n",
        "* keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
      ],
      "metadata": {
        "id": "Aqao92IBbt9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])  # 1번째 리뷰데이터\n",
        "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
        "print('1번째 리뷰 문장 길이: ', len(X_train[0]))\n",
        "print('2번째 리뷰 문장 길이: ', len(X_train[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLsrGVaU5B-L",
        "outputId": "ffe324d0-64c2-4a96-d71f-4251748efa09"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 74, 919, 4, 4, 39, 228, 20, 33, 748]\n",
            "라벨:  0\n",
            "1번째 리뷰 문장 길이:  10\n",
            "2번째 리뷰 문장 길이:  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index['.'])  # 4가 출력됩니다.\n",
        "\n",
        "# 인덱스 0,1,2,3 에는 아무것도 할당되어있지 않습니다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdLSWlff5Cc_",
        "outputId": "3430f7ce-ee2c-4f87-e0be-3edaaab3bf13"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 비어있는 것들에 할당\n",
        "\n",
        "word_to_index[\"<PAD>\"] = 0\n",
        "word_to_index[\"<BOS>\"] = 1\n",
        "word_to_index[\"<UNK>\"] = 2  # unknown\n",
        "word_to_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "index_to_word = {index:word for word, index in word_to_index.items()}\n",
        "\n",
        "print(index_to_word[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBEnlkkm5CZ9",
        "outputId": "6c539c03-455d-460c-a14a-fff0e3abd0c8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<UNUSED>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩된 텍스트가 제대로 디코딩되는지 확인\n",
        "\n",
        "print(get_decoded_sentence(X_train[0], index_to_word))\n",
        "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av7BT3qX8vax",
        "outputId": "6d6f6803-ee7d-4eb6-89ec-51e1f85a4fa1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "더 빙 . . 진짜 짜증 나 네요 목소리\n",
            "라벨:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_data_text = list(X_train) + list(X_test)\n",
        "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
        "num_tokens = [len(tokens) for tokens in total_data_text]\n",
        "num_tokens = np.array(num_tokens)\n",
        "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
        "print('문장길이 평균 : ', np.mean(num_tokens))\n",
        "print('문장길이 최대 : ', np.max(num_tokens))\n",
        "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
        "\n",
        "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "maxlen = int(max_tokens)\n",
        "print('pad_sequences maxlen : ', maxlen)\n",
        "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOJuyss49J1q",
        "outputId": "a64e597a-0399-4385-906f-01d65e3c60c0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장길이 평균 :  15.96938143432699\n",
            "문장길이 최대 :  116\n",
            "문장길이 표준편차 :  12.843571939469296\n",
            "pad_sequences maxlen :  41\n",
            "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 최대 길이를 "
      ],
      "metadata": {
        "id": "vvE5iW9W94KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        value=word_to_index[\"<PAD>\"],\n",
        "                                                        padding='pre', # 혹은 'post'\n",
        "                                                        maxlen=maxlen)\n",
        "\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=word_to_index[\"<PAD>\"],\n",
        "                                                       padding='pre', # 혹은 'post'\n",
        "                                                       maxlen=maxlen)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDJSUVGp-631",
        "outputId": "83c0e5eb-7c4f-4a98-ec23-2a953b9a131c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(146182, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "패딩문자는 최대 길이에 못 미치는 문장이 왔을 때 그 길이를 최대 길이와 같도록 채워주는 단어이다. 이 패딩문자는 문장의 앞 혹은 뒤에 넣는데, 순차적으로 데이터를 처리하는 RNN에서는 가장 마지막에 놓인 단어가 영향력이 크므로 패딩문자를 앞에서부터 채우는 것이 바람직하다."
      ],
      "metadata": {
        "id": "YWjE5wXK_Wj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 및 validation set 구성"
      ],
      "metadata": {
        "id": "xlutut4z_89Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN 모델"
      ],
      "metadata": {
        "id": "hze856n9Fio-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_1 = tf.keras.Sequential()\n",
        "model_1.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_1.add(tf.keras.layers.LSTM(32))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 32로 하였습니다. (변경 가능)\n",
        "model_1.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLKNfAOm_4Ym",
        "outputId": "8855e660-2bce-47c4-ded8-1833b03fcd57"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 16)          160000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                6272      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,361\n",
            "Trainable params: 167,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터셋은 학습용 데이터의 20% 정도가 적당하다고 한다. 따라서 약 20% 에 근접한 3만개로 둔다.\n",
        "\n",
        "# validation set 30000건 분리\n",
        "X_val = X_train[:30000]   \n",
        "y_val = y_train[:30000]\n",
        "\n",
        "# validation set을 제외한 나머지 15000건\n",
        "partial_X_train = X_train[30000:]  \n",
        "partial_y_train = y_train[30000:]\n",
        "\n",
        "print(partial_X_train.shape)\n",
        "print(partial_y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5GpnX1FBi-U",
        "outputId": "259caebc-5ae6-447d-e39e-9cdd7c441de4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(116182, 41)\n",
            "(116182,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_1.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTPCWpdICENV",
        "outputId": "aa7c10e0-594d-4456-da69-7997baf6cb6b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "227/227 [==============================] - 4s 9ms/step - loss: 0.4618 - accuracy: 0.7829 - val_loss: 0.3504 - val_accuracy: 0.8467\n",
            "Epoch 2/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.3338 - accuracy: 0.8582 - val_loss: 0.3437 - val_accuracy: 0.8518\n",
            "Epoch 3/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.3110 - accuracy: 0.8682 - val_loss: 0.3422 - val_accuracy: 0.8517\n",
            "Epoch 4/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2951 - accuracy: 0.8756 - val_loss: 0.3494 - val_accuracy: 0.8479\n",
            "Epoch 5/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2802 - accuracy: 0.8829 - val_loss: 0.3499 - val_accuracy: 0.8525\n",
            "Epoch 6/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2648 - accuracy: 0.8898 - val_loss: 0.3528 - val_accuracy: 0.8518\n",
            "Epoch 7/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2500 - accuracy: 0.8959 - val_loss: 0.3864 - val_accuracy: 0.8499\n",
            "Epoch 8/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2351 - accuracy: 0.9025 - val_loss: 0.3718 - val_accuracy: 0.8506\n",
            "Epoch 9/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.2221 - accuracy: 0.9083 - val_loss: 0.3886 - val_accuracy: 0.8499\n",
            "Epoch 10/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2091 - accuracy: 0.9143 - val_loss: 0.4340 - val_accuracy: 0.8490\n",
            "Epoch 11/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1983 - accuracy: 0.9191 - val_loss: 0.4211 - val_accuracy: 0.8460\n",
            "Epoch 12/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9240 - val_loss: 0.4653 - val_accuracy: 0.8466\n",
            "Epoch 13/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9298 - val_loss: 0.5000 - val_accuracy: 0.8426\n",
            "Epoch 14/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1675 - accuracy: 0.9334 - val_loss: 0.5068 - val_accuracy: 0.8401\n",
            "Epoch 15/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1574 - accuracy: 0.9376 - val_loss: 0.5281 - val_accuracy: 0.8418\n",
            "Epoch 16/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1492 - accuracy: 0.9413 - val_loss: 0.5832 - val_accuracy: 0.8407\n",
            "Epoch 17/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1409 - accuracy: 0.9447 - val_loss: 0.5813 - val_accuracy: 0.8381\n",
            "Epoch 18/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1337 - accuracy: 0.9480 - val_loss: 0.6333 - val_accuracy: 0.8390\n",
            "Epoch 19/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1305 - accuracy: 0.9495 - val_loss: 0.6439 - val_accuracy: 0.8346\n",
            "Epoch 20/20\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9519 - val_loss: 0.6957 - val_accuracy: 0.8356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트셋으로 평가\n",
        "\n",
        "results = model_1.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goP9_rx8DNHe",
        "outputId": "02fd4c9b-34ac-4bc1-be6b-6423e898b527"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 4s - loss: 0.6941 - accuracy: 0.8312 - 4s/epoch - 3ms/step\n",
            "[0.6941249966621399, 0.8312142491340637]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 모델"
      ],
      "metadata": {
        "id": "r0qaMTFrFn3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # 어휘 사전의 크기입니다.\n",
        "word_vector_dim = 16   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
        "\n",
        "model_2 = tf.keras.Sequential()\n",
        "model_2.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_2.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
        "model_2.add(tf.keras.layers.MaxPooling1D(5))\n",
        "model_2.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
        "model_2.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "model_2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model_2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlGuxgMfF0Q7",
        "outputId": "3b8006c3-5262-442d-fe64-b1e27fbb6cfb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, None, 16)          160000    \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, None, 16)          1808      \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, None, 16)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, None, 16)          1808      \n",
            "                                                                 \n",
            " global_max_pooling1d_8 (Glo  (None, 16)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 163,905\n",
            "Trainable params: 163,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_2.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Pi00s0G1y4",
        "outputId": "a54bf893-aa67-4995-d796-0dd06fd53b57"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "227/227 [==============================] - 2s 6ms/step - loss: 0.5153 - accuracy: 0.7224 - val_loss: 0.3558 - val_accuracy: 0.8451\n",
            "Epoch 2/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.3267 - accuracy: 0.8610 - val_loss: 0.3382 - val_accuracy: 0.8544\n",
            "Epoch 3/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.2886 - accuracy: 0.8799 - val_loss: 0.3388 - val_accuracy: 0.8545\n",
            "Epoch 4/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.2561 - accuracy: 0.8971 - val_loss: 0.3489 - val_accuracy: 0.8526\n",
            "Epoch 5/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.2229 - accuracy: 0.9143 - val_loss: 0.3668 - val_accuracy: 0.8523\n",
            "Epoch 6/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9301 - val_loss: 0.3949 - val_accuracy: 0.8474\n",
            "Epoch 7/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.1550 - accuracy: 0.9447 - val_loss: 0.4324 - val_accuracy: 0.8419\n",
            "Epoch 8/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.1266 - accuracy: 0.9568 - val_loss: 0.4737 - val_accuracy: 0.8374\n",
            "Epoch 9/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9659 - val_loss: 0.5313 - val_accuracy: 0.8353\n",
            "Epoch 10/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0873 - accuracy: 0.9726 - val_loss: 0.5728 - val_accuracy: 0.8321\n",
            "Epoch 11/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9769 - val_loss: 0.6271 - val_accuracy: 0.8284\n",
            "Epoch 12/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 0.9807 - val_loss: 0.6699 - val_accuracy: 0.8263\n",
            "Epoch 13/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0561 - accuracy: 0.9833 - val_loss: 0.7135 - val_accuracy: 0.8263\n",
            "Epoch 14/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0494 - accuracy: 0.9855 - val_loss: 0.7585 - val_accuracy: 0.8240\n",
            "Epoch 15/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.8011 - val_accuracy: 0.8221\n",
            "Epoch 16/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9881 - val_loss: 0.8607 - val_accuracy: 0.8210\n",
            "Epoch 17/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.9081 - val_accuracy: 0.8188\n",
            "Epoch 18/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 0.9826 - val_accuracy: 0.8186\n",
            "Epoch 19/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.9865 - val_accuracy: 0.8171\n",
            "Epoch 20/20\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 1.0132 - val_accuracy: 0.8196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  테스트셋으로 평가\n",
        "\n",
        "results = model_2.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZsS10EPH9uf",
        "outputId": "a7d28a47-e653-4514-af71-e1871f3c7423"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 3s - loss: 1.0614 - accuracy: 0.8128 - 3s/epoch - 2ms/step\n",
            "[1.0614217519760132, 0.8127835392951965]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MaxPooling"
      ],
      "metadata": {
        "id": "7tHQ31DZIzot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000  # 어휘 사전의 크기입니다(10개의 단어)\n",
        "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
        "\n",
        "model_3 = tf.keras.Sequential()\n",
        "model_3.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_3.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "model_3.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model_3.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVxdtlrjH9su",
        "outputId": "1b86f043-8054-475b-85ed-4f1b36e6bec2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, None, 4)           40000     \n",
            "                                                                 \n",
            " global_max_pooling1d_10 (Gl  (None, 4)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,049\n",
            "Trainable params: 40,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_u9Vi2bH9qN",
        "outputId": "18ed65c6-88bd-4bf2-b75f-98190980d72e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "227/227 [==============================] - 2s 5ms/step - loss: 0.6568 - accuracy: 0.6916 - val_loss: 0.5706 - val_accuracy: 0.7788\n",
            "Epoch 2/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.4764 - accuracy: 0.8043 - val_loss: 0.4180 - val_accuracy: 0.8148\n",
            "Epoch 3/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3894 - accuracy: 0.8323 - val_loss: 0.3882 - val_accuracy: 0.8255\n",
            "Epoch 4/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8459 - val_loss: 0.3797 - val_accuracy: 0.8294\n",
            "Epoch 5/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3398 - accuracy: 0.8549 - val_loss: 0.3773 - val_accuracy: 0.8325\n",
            "Epoch 6/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8617 - val_loss: 0.3782 - val_accuracy: 0.8325\n",
            "Epoch 7/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3157 - accuracy: 0.8668 - val_loss: 0.3817 - val_accuracy: 0.8325\n",
            "Epoch 8/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3074 - accuracy: 0.8708 - val_loss: 0.3849 - val_accuracy: 0.8320\n",
            "Epoch 9/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.3006 - accuracy: 0.8737 - val_loss: 0.3886 - val_accuracy: 0.8320\n",
            "Epoch 10/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2949 - accuracy: 0.8769 - val_loss: 0.3925 - val_accuracy: 0.8313\n",
            "Epoch 11/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.8792 - val_loss: 0.3967 - val_accuracy: 0.8304\n",
            "Epoch 12/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8812 - val_loss: 0.4011 - val_accuracy: 0.8306\n",
            "Epoch 13/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2830 - accuracy: 0.8829 - val_loss: 0.4049 - val_accuracy: 0.8295\n",
            "Epoch 14/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.8842 - val_loss: 0.4093 - val_accuracy: 0.8295\n",
            "Epoch 15/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2776 - accuracy: 0.8851 - val_loss: 0.4120 - val_accuracy: 0.8282\n",
            "Epoch 16/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.8864 - val_loss: 0.4159 - val_accuracy: 0.8278\n",
            "Epoch 17/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2732 - accuracy: 0.8870 - val_loss: 0.4193 - val_accuracy: 0.8269\n",
            "Epoch 18/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2713 - accuracy: 0.8879 - val_loss: 0.4229 - val_accuracy: 0.8266\n",
            "Epoch 19/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.8884 - val_loss: 0.4254 - val_accuracy: 0.8263\n",
            "Epoch 20/20\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.8893 - val_loss: 0.4281 - val_accuracy: 0.8255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  테스트셋으로 평가\n",
        "\n",
        "results = model_3.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoJEwVP2H9i9",
        "outputId": "9db9c97f-7bc5-498d-b4ca-d7902475a5ac"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 2s - loss: 0.4314 - accuracy: 0.8230 - 2s/epoch - 2ms/step\n",
            "[0.4313792586326599, 0.8229957222938538]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN 모델로 다시 구하기\n",
        "\n",
        "위의 3가지 모델을 사용했을 때 같은 조건에서 가장 성능이 나았던 RNN 모델을 다듬어보자."
      ],
      "metadata": {
        "id": "FhwqDgLPJftH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM units를 늘린 경우\n"
      ],
      "metadata": {
        "id": "mpJrmyVuLpr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터를 바꿔서 다시 시도한다.\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(64))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsywKlCNH9gt",
        "outputId": "6efbd0d2-426a-420b-e421-a7a3797bc2d9"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, None, 16)          160000    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                20736     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 182,849\n",
            "Trainable params: 182,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA0VqzSHJp6b",
        "outputId": "5a345792-9f87-4c47-9284-8c42f54b10df"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "227/227 [==============================] - 4s 9ms/step - loss: 0.4632 - accuracy: 0.7719 - val_loss: 0.3496 - val_accuracy: 0.8472\n",
            "Epoch 2/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.3373 - accuracy: 0.8558 - val_loss: 0.3431 - val_accuracy: 0.8508\n",
            "Epoch 3/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.3161 - accuracy: 0.8664 - val_loss: 0.3422 - val_accuracy: 0.8512\n",
            "Epoch 4/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.3037 - accuracy: 0.8730 - val_loss: 0.3484 - val_accuracy: 0.8491\n",
            "Epoch 5/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2919 - accuracy: 0.8785 - val_loss: 0.3476 - val_accuracy: 0.8502\n",
            "Epoch 6/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2785 - accuracy: 0.8843 - val_loss: 0.3559 - val_accuracy: 0.8448\n",
            "Epoch 7/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2619 - accuracy: 0.8914 - val_loss: 0.3509 - val_accuracy: 0.8494\n",
            "Epoch 8/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2470 - accuracy: 0.8983 - val_loss: 0.3685 - val_accuracy: 0.8509\n",
            "Epoch 9/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2301 - accuracy: 0.9051 - val_loss: 0.3797 - val_accuracy: 0.8506\n",
            "Epoch 10/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2147 - accuracy: 0.9118 - val_loss: 0.4091 - val_accuracy: 0.8481\n",
            "Epoch 11/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2005 - accuracy: 0.9178 - val_loss: 0.4252 - val_accuracy: 0.8472\n",
            "Epoch 12/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1872 - accuracy: 0.9242 - val_loss: 0.4742 - val_accuracy: 0.8466\n",
            "Epoch 13/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1756 - accuracy: 0.9293 - val_loss: 0.4921 - val_accuracy: 0.8436\n",
            "Epoch 14/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1664 - accuracy: 0.9329 - val_loss: 0.5061 - val_accuracy: 0.8414\n",
            "Epoch 15/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1571 - accuracy: 0.9370 - val_loss: 0.5351 - val_accuracy: 0.8381\n",
            "Epoch 16/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1474 - accuracy: 0.9414 - val_loss: 0.5954 - val_accuracy: 0.8410\n",
            "Epoch 17/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1412 - accuracy: 0.9444 - val_loss: 0.6405 - val_accuracy: 0.8391\n",
            "Epoch 18/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1328 - accuracy: 0.9476 - val_loss: 0.6775 - val_accuracy: 0.8335\n",
            "Epoch 19/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1260 - accuracy: 0.9507 - val_loss: 0.6685 - val_accuracy: 0.8325\n",
            "Epoch 20/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1202 - accuracy: 0.9533 - val_loss: 0.7346 - val_accuracy: 0.8371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "워드 벡터의 차원 수를 늘린 경우"
      ],
      "metadata": {
        "id": "WaLDEEJvMlon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터를 바꿔서 다시 시도한다.\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 32  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(32))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpEz08rMJp27",
        "outputId": "9493c995-9b56-4b68-b805-f457de021011"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, None, 32)          320000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,409\n",
            "Trainable params: 329,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTLlnBxEJp0P",
        "outputId": "9fb89423-a446-4aa5-9c21-c4ff699e69f2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "227/227 [==============================] - 4s 10ms/step - loss: 0.4490 - accuracy: 0.7861 - val_loss: 0.3494 - val_accuracy: 0.8499\n",
            "Epoch 2/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.3296 - accuracy: 0.8602 - val_loss: 0.3404 - val_accuracy: 0.8527\n",
            "Epoch 3/20\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 0.3055 - accuracy: 0.8720 - val_loss: 0.3476 - val_accuracy: 0.8509\n",
            "Epoch 4/20\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 0.2843 - accuracy: 0.8820 - val_loss: 0.3398 - val_accuracy: 0.8525\n",
            "Epoch 5/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2673 - accuracy: 0.8908 - val_loss: 0.3478 - val_accuracy: 0.8515\n",
            "Epoch 6/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2478 - accuracy: 0.8990 - val_loss: 0.3629 - val_accuracy: 0.8515\n",
            "Epoch 7/20\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 0.2301 - accuracy: 0.9061 - val_loss: 0.3674 - val_accuracy: 0.8504\n",
            "Epoch 8/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.2114 - accuracy: 0.9146 - val_loss: 0.3942 - val_accuracy: 0.8477\n",
            "Epoch 9/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1971 - accuracy: 0.9203 - val_loss: 0.4123 - val_accuracy: 0.8458\n",
            "Epoch 10/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1827 - accuracy: 0.9271 - val_loss: 0.4821 - val_accuracy: 0.8459\n",
            "Epoch 11/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1691 - accuracy: 0.9320 - val_loss: 0.4977 - val_accuracy: 0.8422\n",
            "Epoch 12/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1595 - accuracy: 0.9357 - val_loss: 0.5052 - val_accuracy: 0.8410\n",
            "Epoch 13/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1491 - accuracy: 0.9407 - val_loss: 0.5712 - val_accuracy: 0.8397\n",
            "Epoch 14/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1375 - accuracy: 0.9455 - val_loss: 0.5925 - val_accuracy: 0.8354\n",
            "Epoch 15/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1295 - accuracy: 0.9489 - val_loss: 0.6458 - val_accuracy: 0.8357\n",
            "Epoch 16/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1212 - accuracy: 0.9525 - val_loss: 0.6876 - val_accuracy: 0.8404\n",
            "Epoch 17/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1151 - accuracy: 0.9546 - val_loss: 0.7897 - val_accuracy: 0.8378\n",
            "Epoch 18/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1092 - accuracy: 0.9569 - val_loss: 0.7492 - val_accuracy: 0.8317\n",
            "Epoch 19/20\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 0.1037 - accuracy: 0.9595 - val_loss: 0.7735 - val_accuracy: 0.8295\n",
            "Epoch 20/20\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 0.0975 - accuracy: 0.9622 - val_loss: 0.8452 - val_accuracy: 0.8303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch size를 줄인 경우"
      ],
      "metadata": {
        "id": "X3czXUd6Mp4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터를 바꿔서 다시 시도한다.\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(32))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMxs2WcdH9eC",
        "outputId": "0147e799-c08b-41bc-d534-b0b23505d617"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, None, 16)          160000    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 32)                6272      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,361\n",
            "Trainable params: 167,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KKvN3SsMvJp",
        "outputId": "fc20c88b-c942-401d-f207-a0f795ec6475"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1816/1816 [==============================] - 13s 6ms/step - loss: 0.3921 - accuracy: 0.8200 - val_loss: 0.3367 - val_accuracy: 0.8530\n",
            "Epoch 2/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.3116 - accuracy: 0.8657 - val_loss: 0.3340 - val_accuracy: 0.8575\n",
            "Epoch 3/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2746 - accuracy: 0.8832 - val_loss: 0.3311 - val_accuracy: 0.8604\n",
            "Epoch 4/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2446 - accuracy: 0.8980 - val_loss: 0.3401 - val_accuracy: 0.8594\n",
            "Epoch 5/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2197 - accuracy: 0.9087 - val_loss: 0.3688 - val_accuracy: 0.8583\n",
            "Epoch 6/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1984 - accuracy: 0.9200 - val_loss: 0.3878 - val_accuracy: 0.8550\n",
            "Epoch 7/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1786 - accuracy: 0.9287 - val_loss: 0.4129 - val_accuracy: 0.8529\n",
            "Epoch 8/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1611 - accuracy: 0.9360 - val_loss: 0.4525 - val_accuracy: 0.8512\n",
            "Epoch 9/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1452 - accuracy: 0.9434 - val_loss: 0.5075 - val_accuracy: 0.8516\n",
            "Epoch 10/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1321 - accuracy: 0.9484 - val_loss: 0.5249 - val_accuracy: 0.8504\n",
            "Epoch 11/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.5583 - val_accuracy: 0.8440\n",
            "Epoch 12/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.6458 - val_accuracy: 0.8446\n",
            "Epoch 13/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1032 - accuracy: 0.9602 - val_loss: 0.6455 - val_accuracy: 0.8429\n",
            "Epoch 14/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0950 - accuracy: 0.9635 - val_loss: 0.6946 - val_accuracy: 0.8420\n",
            "Epoch 15/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0877 - accuracy: 0.9666 - val_loss: 0.7197 - val_accuracy: 0.8399\n",
            "Epoch 16/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0841 - accuracy: 0.9678 - val_loss: 0.8446 - val_accuracy: 0.8409\n",
            "Epoch 17/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0772 - accuracy: 0.9704 - val_loss: 0.8118 - val_accuracy: 0.8378\n",
            "Epoch 18/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0733 - accuracy: 0.9718 - val_loss: 0.8128 - val_accuracy: 0.8412\n",
            "Epoch 19/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0686 - accuracy: 0.9738 - val_loss: 0.8751 - val_accuracy: 0.8373\n",
            "Epoch 20/20\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.0646 - accuracy: 0.9751 - val_loss: 0.9700 - val_accuracy: 0.8354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "세 가지 경우를 종합한다. Epoch가 얼마 되지 않아도 val_loss가 늘어나므로 줄여서 시도한다. "
      ],
      "metadata": {
        "id": "cVBrC5CtPHDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터를 바꿔서 다시 시도한다.\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 32  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(64))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JffFIm4EMvHR",
        "outputId": "3167bc98-deb2-4ab3-b89e-a0c271c7932c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, None, 32)          320000    \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,945\n",
            "Trainable params: 346,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XByU0wvPMvD_",
        "outputId": "fc2573a1-671c-4638-dc17-215bda60acee"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1816/1816 [==============================] - 13s 6ms/step - loss: 0.3852 - accuracy: 0.8253 - val_loss: 0.3390 - val_accuracy: 0.8514\n",
            "Epoch 2/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.3022 - accuracy: 0.8703 - val_loss: 0.3196 - val_accuracy: 0.8614\n",
            "Epoch 3/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2634 - accuracy: 0.8882 - val_loss: 0.3255 - val_accuracy: 0.8633\n",
            "Epoch 4/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2332 - accuracy: 0.9028 - val_loss: 0.3392 - val_accuracy: 0.8564\n",
            "Epoch 5/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2064 - accuracy: 0.9164 - val_loss: 0.3645 - val_accuracy: 0.8549\n",
            "Epoch 6/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1812 - accuracy: 0.9271 - val_loss: 0.4094 - val_accuracy: 0.8578\n",
            "Epoch 7/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1582 - accuracy: 0.9363 - val_loss: 0.4546 - val_accuracy: 0.8540\n",
            "Epoch 8/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1392 - accuracy: 0.9444 - val_loss: 0.4959 - val_accuracy: 0.8535\n",
            "Epoch 9/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1234 - accuracy: 0.9514 - val_loss: 0.5434 - val_accuracy: 0.8513\n",
            "Epoch 10/10\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.1087 - accuracy: 0.9566 - val_loss: 0.6284 - val_accuracy: 0.8461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트셋으로 평가\n",
        "\n",
        "results = model_RNN.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxxiOCcURsWC",
        "outputId": "04835236-dc27-4940-d992-d759eefbf559"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 4s - loss: 0.6194 - accuracy: 0.8445 - 4s/epoch - 3ms/step\n",
            "[0.6194473505020142, 0.8444575667381287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5xvvDV_RsTH",
        "outputId": "88bebe7a-323a-46f7-a48d-d59672e852be"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\"는 \"파란색 점\"입니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b는 \"파란 실선\"입니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3TUPQFBfRsQ2",
        "outputId": "9c7d9653-d200-44ac-fd84-3aeb51ce2ee6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그림을 초기화합니다\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ksFMBnUbRsOU",
        "outputId": "5c211494-9352-4cfb-cc22-287a109ad8d5"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 결과로 epoch는 3이 적절하다는 사실을 알 수 있다. 따라서 다시 해보면..."
      ],
      "metadata": {
        "id": "l03nF7DHTwE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터를 바꿔서 다시 시도한다.\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 32  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(64))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrjQxl8KT3kr",
        "outputId": "786ad5c6-5371-4a32-e91e-711a2d0ebe1c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, None, 32)          320000    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 346,945\n",
            "Trainable params: 346,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=3  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcxzWfErT3ip",
        "outputId": "c44b915d-2a5b-4c93-9f04-ae4194a554b8"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1816/1816 [==============================] - 13s 6ms/step - loss: 0.3856 - accuracy: 0.8237 - val_loss: 0.3397 - val_accuracy: 0.8506\n",
            "Epoch 2/3\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.3033 - accuracy: 0.8707 - val_loss: 0.3192 - val_accuracy: 0.8613\n",
            "Epoch 3/3\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.2629 - accuracy: 0.8898 - val_loss: 0.3200 - val_accuracy: 0.8616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트셋으로 평가\n",
        "\n",
        "results = model_RNN.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oykrSithT3Nq",
        "outputId": "14a12c9a-b31d-431a-bf16-23b704c87997"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 4s - loss: 0.3281 - accuracy: 0.8574 - 4s/epoch - 3ms/step\n",
            "[0.32809677720069885, 0.8573957085609436]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습된 Embedding layer 분석"
      ],
      "metadata": {
        "id": "votl9O28UvgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = model_RNN.layers[0]\n",
        "weights = embedding_layer.get_weights()[0]\n",
        "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJlMLiOXU1HQ",
        "outputId": "81198f62-5005-4fd9-e9b2-e6a0ab2ecc41"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
        "word2vec_file_path = '/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/word2vec_1.txt'\n",
        "f = open(word2vec_file_path, 'w')\n",
        "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
        "\n",
        "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
        "vectors = model_RNN.get_weights()[0]\n",
        "for i in range(4,vocab_size):\n",
        "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "9o4FCl2UU1Fe"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "\n",
        "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
        "vector = word_vectors['추천']\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn04OGSMU1DX",
        "outputId": "a1bf193e-ac9e-4ea1-82a1-587c78086f68"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03683658, -0.0971084 ,  0.07998341,  0.07281753, -0.1147862 ,\n",
              "       -0.10304193,  0.03124219, -0.01816459,  0.11426818,  0.06344908,\n",
              "       -0.07482395,  0.10273682, -0.0632188 ,  0.14141493,  0.08515199,\n",
              "       -0.05612532,  0.05755341,  0.17269255,  0.07847835,  0.08741249,\n",
              "        0.13578814,  0.07574377,  0.10940658, -0.06959734,  0.16031128,\n",
              "       -0.0938124 , -0.13187625,  0.08096723, -0.11262145, -0.08729053,\n",
              "       -0.08283718, -0.06959382], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similar_by_word(\"추천\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOEFMs6BU0va",
        "outputId": "0ff06b6b-e4c5-49fb-a86f-d0041c89929c"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('펭귄', 0.9661002159118652),\n",
              " ('되돌아보', 0.9640968441963196),\n",
              " ('끝장', 0.9636724591255188),\n",
              " ('아려', 0.9624024629592896),\n",
              " ('따스', 0.9614100456237793),\n",
              " ('해냈', 0.9608798027038574),\n",
              " ('울림', 0.9597383737564087),\n",
              " ('슬퍼요', 0.9592797160148621),\n",
              " ('아름다워요', 0.9590615034103394),\n",
              " ('눈물나', 0.958731472492218)]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 Word2Vec 임베딩 활용하여 성능 개선"
      ],
      "metadata": {
        "id": "fypHFeiHVl-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "word2vec_path = '/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/word2vec_ko.model' \n",
        "word2vec = gensim.models.Word2Vec.load(word2vec_path)"
      ],
      "metadata": {
        "id": "u0Mh1q2XU0zz"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
        "word_vectors = Word2VecKeyedVectors.load(word2vec_path)\n",
        "vector = word_vectors.wv['추천']\n",
        "print(len(vector))\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQVqeLyYmuP",
        "outputId": "1a45abd7-77e8-44df-ee33-b68a95f049fb"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.58269382e+00,  6.40746236e-01, -1.53450882e+00, -2.83654690e+00,\n",
              "       -2.43265837e-01, -1.31797469e+00,  1.63202512e+00, -8.36927593e-01,\n",
              "       -4.50154334e-01,  1.17610300e+00,  2.14729571e+00,  8.05107117e-01,\n",
              "       -1.16370988e+00, -1.79936600e+00,  2.15869141e+00,  1.20916033e+00,\n",
              "        1.75766662e-01, -1.87189877e+00,  1.13454318e+00, -3.67186666e-01,\n",
              "       -1.80770779e+00,  1.07534111e+00,  4.37266454e-02, -6.28859043e+00,\n",
              "       -2.44364858e+00, -1.31413686e+00, -1.19013870e+00, -1.44853306e+00,\n",
              "        8.38042080e-01, -1.38884342e+00, -5.00943327e+00,  4.11244154e+00,\n",
              "        1.66292834e+00, -8.70976925e-01, -1.95594096e+00,  2.33000755e+00,\n",
              "        3.58346216e-02, -6.45447910e-01,  9.93417680e-01,  2.24508429e+00,\n",
              "       -2.20631289e+00,  1.40667903e+00, -1.52458799e+00, -8.92117560e-01,\n",
              "       -1.75378513e+00, -1.09110498e+00,  6.55998826e-01, -6.79832339e-01,\n",
              "        2.88972211e+00,  3.91617030e-01,  2.32772565e+00, -1.11888373e+00,\n",
              "        3.78289253e-01, -1.30313492e+00,  1.33023953e+00, -2.01961374e+00,\n",
              "       -7.22886741e-01, -1.16803035e-01,  1.06517307e-01,  2.20069361e+00,\n",
              "       -1.51094341e+00,  1.16659954e-01,  1.23415983e+00,  4.16335136e-01,\n",
              "       -3.44454622e+00,  6.49638951e-01,  1.44054186e+00, -4.27420235e+00,\n",
              "        1.05082440e+00, -2.46142149e+00,  3.12798381e-01, -7.04625249e-01,\n",
              "        8.11914206e-01,  2.37292957e+00, -2.93950796e+00, -2.58756638e-01,\n",
              "        2.94159725e-03, -1.91128027e+00, -4.54321098e+00,  3.05529428e+00,\n",
              "       -3.92513204e+00, -3.34103674e-01,  1.13453555e+00,  1.83969706e-01,\n",
              "       -1.61270738e+00, -7.29900002e-01,  1.76386619e+00, -5.82992911e-01,\n",
              "       -1.09573698e+00, -1.22567642e+00, -5.99079967e-01, -2.74643850e+00,\n",
              "        1.71184707e+00, -5.21157622e-01,  2.10145259e+00,  9.14461434e-01,\n",
              "       -1.59604883e+00, -9.71976280e-01, -2.06440449e+00, -1.39870453e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.similar_by_word(\"추천\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R03EKjCsU0yC",
        "outputId": "da004879-ecc0-444b-f5a7-16685f728f44"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('천거', 0.7103838920593262),\n",
              " ('초빙', 0.687961220741272),\n",
              " ('초청', 0.6826258897781372),\n",
              " ('위촉', 0.6571412086486816),\n",
              " ('포상', 0.6499664783477783),\n",
              " ('선출', 0.6489635705947876),\n",
              " ('소개', 0.6427397727966309),\n",
              " ('임명', 0.6394351720809937),\n",
              " ('등용', 0.6328903436660767),\n",
              " ('추대', 0.6315879225730896)]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전의 결과와는 달리 영화와는 전혀 관계없는 의미로 유사한 단어들이 나열되고 있다."
      ],
      "metadata": {
        "id": "HcV0yWYsXsGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, word_vector_dim))\n",
        "\n",
        "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
        "for i in range(4,vocab_size):\n",
        "    if index_to_word[i] in word2vec:\n",
        "        embedding_matrix[i] = word2vec[index_to_word[i]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL3Ry4kdgPPi",
        "outputId": "d9701028-d229-4c8a-c742-42658dfc6c11"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
        "word_vector_dim = 100  # 워드 벡터의 차원 수 \n",
        "\n",
        "# model 설계 \n",
        "model_RNN = tf.keras.Sequential()\n",
        "model_RNN.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, embeddings_initializer=Constant(embedding_matrix), input_shape=(None,)))\n",
        "model_RNN.add(tf.keras.layers.LSTM(64))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. \n",
        "model_RNN.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_RNN.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
        "\n",
        "model_RNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFfNUE0kZ1f6",
        "outputId": "a6ed25c5-cb11-425d-b435-32afd0bd859b"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_25 (Embedding)    (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 64)                42240     \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,044,353\n",
            "Trainable params: 1,044,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_RNN.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "epochs=3  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
        "\n",
        "history = model_RNN.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id1t2lZNYSk-",
        "outputId": "09daec47-0b18-496f-dde1-556a92fa1a05"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1816/1816 [==============================] - 13s 6ms/step - loss: 0.4151 - accuracy: 0.8061 - val_loss: 0.3445 - val_accuracy: 0.8484\n",
            "Epoch 2/3\n",
            "1816/1816 [==============================] - 11s 6ms/step - loss: 0.3130 - accuracy: 0.8655 - val_loss: 0.3301 - val_accuracy: 0.8580\n",
            "Epoch 3/3\n",
            "1816/1816 [==============================] - 12s 7ms/step - loss: 0.2761 - accuracy: 0.8832 - val_loss: 0.3290 - val_accuracy: 0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  테스트셋으로 평가\n",
        "\n",
        "results = model_RNN.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_B2pjRQRsMQ",
        "outputId": "9045a627-bd36-4275-a1a8-baf7e5caf94a"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 4s - loss: 0.3373 - accuracy: 0.8593 - 4s/epoch - 3ms/step\n",
            "[0.33734267950057983, 0.8592672348022461]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
        "word2vec_file_path2 = '/content/drive/MyDrive/아이펠 데이터/sentiment_classification/data/word2vec_2.txt'\n",
        "f = open(word2vec_file_path2, 'w')\n",
        "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
        "\n",
        "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
        "vectors = model_RNN.get_weights()[0]\n",
        "for i in range(4,vocab_size):\n",
        "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "5hDISiHHiIe5"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path2, binary=False)\n",
        "vector = word_vectors['추천']\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl5u-ALiiIck",
        "outputId": "59d15b87-3638-452c-a6d0-09752e1e7555"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.606924  ,  0.66163373, -1.630613  , -2.7248912 , -0.21215604,\n",
              "       -1.3284479 ,  1.7047087 , -0.850731  , -0.47376782,  1.2628481 ,\n",
              "        2.180031  ,  0.75528514, -1.1280925 , -1.926974  ,  2.1859221 ,\n",
              "        1.1420671 ,  0.23162097, -2.0252285 ,  1.0394294 , -0.46877572,\n",
              "       -1.8265017 ,  1.0216417 ,  0.03297603, -6.2607903 , -2.4298918 ,\n",
              "       -1.3530211 , -1.2682607 , -1.4734069 ,  0.8002041 , -1.4817423 ,\n",
              "       -5.1362324 ,  4.1985846 ,  1.5777158 , -0.90939796, -1.956819  ,\n",
              "        2.2503593 ,  0.09167702, -0.5804335 ,  0.91034424,  2.4594378 ,\n",
              "       -2.2400112 ,  1.4707326 , -1.2820826 , -0.78983396, -1.846615  ,\n",
              "       -1.304921  ,  0.64380264, -0.6325787 ,  2.9882832 ,  0.40210694,\n",
              "        2.3759713 , -1.0066    ,  0.4309378 , -1.2456561 ,  1.4663724 ,\n",
              "       -2.0310788 , -0.59325814, -0.01222878,  0.15510063,  2.2005265 ,\n",
              "       -1.538867  ,  0.20867622,  1.244252  ,  0.31029272, -3.3180206 ,\n",
              "        0.7199367 ,  1.440328  , -4.1748705 ,  1.0264773 , -2.4271731 ,\n",
              "        0.3751382 , -0.6599981 ,  0.86306727,  2.2953804 , -2.9123497 ,\n",
              "       -0.3325687 , -0.06993153, -1.8677527 , -4.443502  ,  2.9757583 ,\n",
              "       -3.915859  , -0.3680917 ,  1.176465  ,  0.1685057 , -1.7376745 ,\n",
              "       -0.83336186,  1.6898668 , -0.44713068, -1.0807052 , -1.2553064 ,\n",
              "       -0.6456395 , -2.7068734 ,  1.6693047 , -0.6334935 ,  2.150857  ,\n",
              "        0.72513396, -1.62535   , -0.99314016, -2.1499968 , -1.3524297 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors.similar_by_word(\"추천\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnSEVDDViRR0",
        "outputId": "48757fef-8ed2-4683-8cf3-57d36a8cdba5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('소개', 0.6391516327857971),\n",
              " ('선정', 0.6220725178718567),\n",
              " ('초대', 0.6108789443969727),\n",
              " ('부탁', 0.5986571311950684),\n",
              " ('심사', 0.5816296339035034),\n",
              " ('선택', 0.5801743268966675),\n",
              " ('요청', 0.5671523809432983),\n",
              " ('설득', 0.5653015375137329),\n",
              " ('평가', 0.5649893879890442),\n",
              " ('지도', 0.5458502769470215)]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과\n",
        "\n",
        "학습된 Embedding layer : 85.7%의 정확도\n",
        "\n",
        "한국어 Word2Vec 임베딩 : 85.9%의 정확도"
      ],
      "metadata": {
        "id": "GmGQ8g0ahX0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "\n",
        "이번 노드에서는 영화 리뷰들을 임베딩하여 그 리뷰가 긍정적인 리뷰인지 혹은 부정적인 리뷰인지 분석하는 일을 했다. 리뷰에 쓰인 문장들의 단어들을 인덱스화 하고 이것들을 이용해 학습했다. 여기서 같은 단어를 사용한다 하더라도 맥락에 따라 전혀 다른 의미를 내포하고 있을 수 있다는 점을 기억해야한다. 예를 들어 같은 단어를 사용한 평가라도 영화의 장르에 따라 맥락이 다르고, 리뷰에 쓰인 자연어인 만큼 반어법적인 표현도 많을 수 있기 때문이다. 그러므로 이 맥락을 찾는 것이 중요하다 할 수 있겠다.\n",
        "\n",
        "처음에 3가지 모델을 테스트해보았는데 RNN 모델이 가장 나은 결과를 보여주어 RNN 모델을 선택했지만 사실 CNN모델이나 MaxPooling 레이어 하나만 쓴 모델도 나쁘지 않은 결과를 보여주었다. 저 두 모델은 RNN 모델보다 훨씬 가벼워서 학습속도가 빠르므로 서로 장단점이 있다고 할 수 있겠다. 하지만 우리는 학습속도는 그리 중요하지 않았으며 이번 노드에서 했던 정도는 크게 오래 걸리지 않고 가능했으므로 RNN 모델을 썼다.\n",
        "\n",
        "여기서 우리가 학습해 만든 임베딩 레이어와 미리 만들어진 word2vec 임베딩을 사용하는 것 모두 해보았는데 학습으로 만든 레이어는 영화와 관련있는 내용들을 주로 학습한 반면 외부에서 가져온 단어 사전은 일상적인 언어로 되어있는 차이점이 있었다. 예를 들어 '추천' 이라는 단어를 넣었을 때 우리가 학습한 레이어는 좋은 영화와 관련된 단어들을 유사한 단어로 뽑는 반면, 미리 준비된 사전에서는 사전적인 의미로 비슷한 단어들을 가져왔다.\n",
        "\n",
        "물론 여기까지 본다면 우리가 학습한 레이어가 훨씬 적합하다고 볼 수 있겠지만 저 외부 임베딩을 베이스로 하여 학습을 진행할 수도 있는 것이다. 이렇게 한다면 사전적인 의미를 이미 가지고 있으므로 훨씬 단어에 대한 정확도가 올라갈 것을 기대할 수 있겠다. 실제로 사용해보면 0.2%p 정확도가 올라갔는데 의미가 없진 않지만 큰 차이는 아니라 아쉬웠다."
      ],
      "metadata": {
        "id": "C2duDJjvh-Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "https://wikidocs.net/80437 다양한 모델들"
      ],
      "metadata": {
        "id": "662lGmtwIStO"
      }
    }
  ]
}